---
layout: post
title: Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems
date:   2023-12-09 14:26
description: REDE search detector ë…¼ë¬¸ ì„¤ëª… & êµ¬í˜„
comments: true
tags:
- paper
- RAG
---
[ì›ë³¸ ë…¼ë¬¸](https://arxiv.org/pdf/2109.08820.pdf)

# ë¬´ì—‡ì— ëŒ€í•œ ë…¼ë¬¸ì¸ê°€

ì¼ë‹¨ Knowledge-seeking Turn Detectionì´ ë¬´ì—‡ì¸ê°€ë¶€í„° ì•Œ í•„ìš”ê°€ ìžˆë‹¤. aiëž‘ ì‚¬ëžŒì´ ëŒ€í™”ë¥¼ í•˜ë‹¤ ë³´ë©´, ëª¨ë“  ëŒ€í™”ì—ì„œ retrievalì„ í•´ì•¼ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë‹¤. ì–´ë–¨ ë•ŒëŠ” ê·¸ëƒ¥ ê³ ë§™ë‹¤ê³  í•  ìˆ˜ë„, ì•„ë‹ˆë©´ ì´ë¯¸ ìžˆëŠ” ì •ë³´ì—ì„œ ë¬¼ì–´ë³¼ ìˆ˜ ìžˆëŠ” ê²ƒì´ë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´ ë³´ìž.
ì¸ê³µì§€ëŠ¥ì—ê²Œ ê°ìŠ¤íŠ¸ì— ëŒ€í•´ ë¬¼ì–´ë³´ëŠ” ìƒí™©ì´ê³ , ì¸ê³µì§€ëŠ¥ì€ ì´ë¯¸ ê°ìŠ¤íŠ¸ì˜ ë‚˜ë¬´ìœ„í‚¤ ë¬¸ì„œë¥¼ ëª¨ë‘ ì•Œê³  ìžˆëŠ” ìƒíƒœì´ë‹¤. 

```
ìœ ì € : ê°ìŠ¤íŠ¸ëŠ” ë­í•˜ëŠ” ì‚¬ëžŒì´ì•¼?
ì¸ê³µì§€ëŠ¥ : ê°ìŠ¤íŠ¸ëŠ” ì¸í„°ë„· ë°©ì†¡ì¸ìœ¼ë¡œ, ì£¼ë¡œ ê²Œìž„ì´ë‚˜ ì¶•êµ¬ì™€ ê´€ë ¨ëœ ë°©ì†¡ì„ í•©ë‹ˆë‹¤.
ìœ ì € : ê·¸ëŸ¬ë©´ ë¬´ìŠ¨ ì¶•êµ¬íŒ€ì„ ì‘ì›í•˜ëŠ”ë°?
ì¸ê³µì§€ëŠ¥ : ê°ìŠ¤íŠ¸ëŠ” EPLì˜ ë§¨ì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œì™€ í•œêµ­ êµ­ê°€ëŒ€í‘œíŒ€ì„ ì£¼ë¡œ ì‘ì›í•©ë‹ˆë‹¤.
ìœ ì € : ê·¸ë ‡êµ¬ë§Œ. ë­ ê°ìŠ¤íŠ¸ ì™„ì „ ë¹¡ë¹¡ì´ì— ëª¨ì†”ì²˜ëŸ¼ ìƒê²¼ëŠ”ë°. ìœ íŠœë¸Œ êµ¬ë…ìžëŠ” ì—„ì²­ ë§Žë„¤ ã„·ã„·
ì¸ê³µì§€ëŠ¥ : ì•„ë‹™ë‹ˆë‹¤. ê°ìŠ¤íŠ¸ëŠ” ëª¨íƒœ ì†”ë¡œê°€ ì•„ë‹ˆë©°, ìœ íŠœë²„ ëšœë°¥ê³¼ ê²°í˜¼ì„ ë°œí‘œí•œ ìƒíƒœìž…ë‹ˆë‹¤.
ìœ ì € : ëšœë°¥ì€ ë­í•˜ëŠ” ì‚¬ëžŒì¸ë°? ìœ íŠœë²„ë©´ ë¬´ìŠ¨ ë°©ì†¡í•´?
```

ìœ„ ëŒ€í™”ì—ì„œ ìœ ì €ì˜ 1~3ë²ˆì§¸ ì§ˆë¬¸ì€ ëª¨ë‘ ê°ìŠ¤íŠ¸ ë‚˜ë¬´ìœ„í‚¤ì— ë‚˜ì™€ìžˆëŠ” ë‚´ìš©ë“¤ì´ë‹¤. ê·¸ëŸ°ë°, ë§ˆì§€ë§‰ ì§ˆë¬¸ì€ ê°ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ëšœë°¥ì— ëŒ€í•´ì„œ ë¬¼ì–´ë³´ê³  ìžˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ë‚˜ë¬´ìœ„í‚¤ì— ë‚˜ì™€ ìžˆì§€ ì•Šê¸° ë•Œë¬¸ì—, ëšœë°¥ ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ëšœë°¥ì— ëŒ€í•œ ë‚´ìš©ì„ ê°€ì ¸ì™€ì•¼ ë˜ëŠ” ê²ƒì´ë‹¤. 
ë°”ë¡œ 1~3ë²ˆì§¸ ì§ˆë¬¸ì´ Non-knowledge seeking turnì´ê³ , ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ **knowledge seeking turn**ì´ë‹¤. 
ì¦‰, **ê²€ìƒ‰ì´ ë§ˆë ¤ìš´ ìƒí™©**ì´ knowledge seeking turnì´ë‹¤.

ê·¸ëŸ¬ë©´ ì›ëž˜ ì–´ë–»ê²Œ ê²€ìƒ‰ì´ ë§ˆë ¤ìš´ ìƒí™©ì„ ë§ˆë µë‹¤ê³  ì¸ê³µì§€ëŠ¥ì´ ì¸ì§€í•˜ê²Œ í–ˆì„ê¹Œ? ì¦‰, ì–´ë–»ê²Œ knowledge seeking turnì„ detectioní–ˆì„ê¹Œ?

ê°„ë‹¨í•˜ë‹¤. ë§ˆë ¤ìš´ ìƒí™©ê³¼ ë§ˆë µì§€ ì•Šì€ ìƒí™©ë“¤ì˜ ëŒ€í™”ë¥¼ ë‹¤ ì£¼ê³ , labelì„ ì¤€ë‹¤ìŒì—, BERTì™€ ê°™ì€ ëª¨ë¸ì„ ì´ìš©í•´ binary classifierë¡œ í›ˆë ¨ì‹œí‚¤ë©´ ê·¸ë§Œì´ë‹¤. ì°¸ ì‰½ì£ ?

ê·¼ë°, ë¬¸ì œëŠ” ìœ„ì™€ ê°™ì€ ëŒ€í™”ë“¤ê³¼ ê·¸ê²ƒì— ëŒ€í•œ labelì´ ë‹¤ ìžˆì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ë ‡ê²Œ ê²€ìƒ‰ì´ ë§ˆë ¤ìš´ì§€ íŒë‹¨í•˜ëŠ” ê²ƒì€ ì–´ëŠ RAG ì‹œìŠ¤í…œì´ë“  í•„ìš”í•  ê²ƒ ê°™ì€ë°, ê° ë¶„ì•¼ë§ˆë‹¤ ë°ì´í„° ë§Œë“¤ê³  ìžˆëŠ” ê²ƒì€ ì—ë°” ì•„ë‹Œê°€?

ê·¸ëž˜ì„œ zero shot ë° few shotìœ¼ë¡œ knowledge-seeking turn detectionì„ ë§Œë“¤ì—ˆë‹¤ëŠ” ê²ƒì´ ë³¸ ë…¼ë¬¸ì˜ ë‚´ìš©ì´ë‹¤. a.k.a ê²€ìƒ‰ ë§ˆë ¤ìš´ ìƒí™© ëª‡ ê°œë§Œ ë³´ê³  ê²€ìƒ‰ ë§ˆë ¤ìš´ ìƒí™© ê°ì§€ê¸° ë§Œë“¤ê¸°!


# ê·¸ëŸ¬ë©´ ì–´ì¼€í–ˆëˆ„

ì´ì œ ë…¼ë¬¸ì—ì„œ ì–´ë–»ê²Œ zero-shot í˜¹ì€ few-shot ë§Œìœ¼ë¡œ ê²€ìƒ‰ì„ í• ê²ƒì¸ì§€ ë§ê²ƒì¸ì§€ ê²°ì •í–ˆëŠ”ì§€ ë´ë³´ìž. 

ì„¸ ê°€ì§€ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì§„ë‹¤. 
Encoder Adaptation â‡’ Representation Transformation â‡’ Density estimation

## 1. Encoder Adaptation
Non-knowledge seeking turn ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ì¼ë°˜ ëª¨ë¸ í›ˆë ¨í•˜ë“¯ì´ í† í° ê°€ë ¤ê°€ë©° generation í›ˆë ¨í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ëƒ¥ ëŒ€í™” ê°€ì ¸ë‹¤ê°€ íŒŒì¸ íŠœë‹ í–ˆë‹¤ê³  ìƒê°í•˜ë©´ ê°„ë‹¨í•˜ë‹¤. ê·¸ê²Œ ë‹¤ìž„.

## 2. Representation Transformation

ìœ„ ëª¨ë¸ì—ì„œ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ê°„ë‹¨í•œ (?) ì„ í˜• ë³€í™˜ìœ¼ë¡œ ë³€ê²½í•´ì£¼ëŠ” ê³¼ì •ì´ë‹¤. ì´ê²Œ ë­” ë©ë©ì´ ì†Œë¦¬ì¸ê°€ ì‹¶ê² ì§€ë§Œ, ëŒ€ì¶© ë‚˜ë„ ë¹„ìŠ·í•˜ê²Œ ìƒê°í•œë‹¤. 

![](https://velog.velcdn.com/images/vkehfdl1/post/04e46ad8-1e5a-40dc-b8e1-56e76e52adbf/image.gif)

ëŒ€ì¶© ë³¸ì¸ë„ ìž˜ ì´í•´ ëª»í–ˆê¸° ë•Œë¬¸ì— ì„¤ëª…ì´ ì–´ë ¤ìš¸ ìˆ˜ ìžˆë‹¤. ê·¸ë¦¬ê³  ìž˜ëª»ëœ ë‚´ìš©ì´ ìžˆì„ìˆ˜ë„ ìžˆë‹¤... ë³¸ì¸ì˜ ëŠ¥ì§€ ì´ìŠˆë‹ˆ ì°©í•˜ê²Œ ë´ì£¼ì‹œê¸¸ ðŸ™

ì¼ë‹¨ ìˆ˜ì‹ì„ ë³´ê¸° ì „ì— ì•Œì•„ì•¼ í•  ê²ƒì´ ìžˆë‹¤. 
1. ì´ ì„ í˜• ë³€í™˜ ê³¼ì •ì€ knowledge-seeking sentence, ì¦‰ ì´ë¯¸ ê²€ìƒ‰ì´ ë§ˆë ¤ì›Œì§€ëŠ” ì§ˆë¬¸ë“¤ ëª‡ ê°œë¥¼ ê°€ì§€ê³  íŠ¹ì • ì„ í˜• ë³€í™˜ì„ ì°¾ëŠ” ê²ƒì´ë‹¤. 


ì´ì œ ìˆ˜ì‹ì„ ë³´ìž.
$$
\tilde{e} = T(e) = (e - \mu)W
$$

ìš°ë¦¬ëŠ” $\tilde{e}$ë¥¼ êµ¬í•´ì•¼ í•œë‹¤.
ê·¸ëŸ¬ë©´, ì—¬ê¸°ì„œ $\mu$ê°€ ë­ëƒ? WëŠ” ì–´ë–»ê²Œ êµ¬í•˜ëŠëƒ? ë°”ë¡œ ì´ë ‡ê²Œë‹¤.

$$
\mu = \frac{1}{M}\sum^{M}_{i=1}{E(x_i^K)}
$$

ì¼ë‹¨, $x_i^K$ëŠ” knowledge seeking turn ë¬¸ìž¥ë“¤ì˜ $i$ë²ˆì§¸ ë¬¸ìž¥ì´ë‹¤. ê·¸ë¦¬ê³  $E$ëŠ” ì¸ì½”ë”ì¸ë°, íŠ¹ì • ë²¡í„°ë¥¼ ë‚´ë†“ëŠ” ëª¨ë¸ì„ ìƒê°í•˜ë©´ íŽ¸í•˜ë‹¤. ê·¸ëŸ¬ë©´ $E(x_i^K)$ëŠ” ê·¸ ì¸ì½”ë”ë¥¼ ì§€ë‚˜ì„œ ë‚˜ì˜¨ ë²¡í„°ì´ë‹¤. ê·¸ê²ƒì„ $M$ë²ˆì§¸ ë¬¸ìž¥ê¹Œì§€ ë”í•˜ê³  ë‹¤ì‹œ $M$ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì¤€ ê²ƒì´ë‹ˆê¹, $\mu$ëŠ” knowledge seeking turn ë¬¸ìž¥ë“¤ì˜ ì¸ì½”ë”ë¥¼ ì§€ë‚œ í‰ê·  ë²¡í„°ì´ë‹¤.

ì¢‹ë‹¤. $\mu$ëŠ” í‰ê· ë²¡í„°ì´ë‹¤. ê·¸ëŸ¬ë©´ ì´ì œ $W$ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ ì¼ë‹¨ covariance(ê³µë¶„ì‚°) í–‰ë ¬ì„ êµ¬í•œë‹¤. ì´ê²ƒì„ í•˜ë©´ knowledge seeking turn ë¬¸ìž¥ë“¤ì˜ íŠ¹ì„±ë“¤ì´ ë‚˜ì˜¤ëŠ” ê²ƒì´ë‹¤. ì´ë ‡ê²Œ êµ¬í•œë‹¤.
$$
\sum = \frac{1}{M}\sum^{M}_{i=1}(E(x_i^K) - \mu)^{T}(E(x_i^K) - \mu)
$$

ê·¸ëŸ° ë‹¤ìŒì—, SVD (Singular Value Decomposition)ì„ ìˆ˜í–‰í•œë‹¤. 
$$
\sum = U\Lambda{U}^T
$$

ê·¸ë ‡ê²Œ $W$ë¥¼ êµ¬í•  ìˆ˜ ìžˆë‹¤..!
$$
W = U\sqrt{\Lambda^{-1}}
$$

ë§ˆì§€ë§‰ìœ¼ë¡œ, $W$ì˜ ì²« $L$ê°œì˜ columnì„ ìž˜ë¼ë‚´ì„œ ì‚¬ìš©í•˜ë©´ PCAëž‘ ë¹„ìŠ·í•˜ê²Œ ì°¨ì›ì€ ì¤„ì´ë©´ì„œ ì„±ëŠ¥ì€ ìœ ì§€í•  ìˆ˜ ìžˆë‹¤ëŠ”ë°, ì €ìžë“¤ì˜ ì‹¤í—˜ì— ë”°ë¥´ë©´ 300ì°¨ì› ì •ë„ë¡œ í•´ë„ 95%ëŠ” ì„±ëŠ¥ì´ ë‚˜ì™”ë‹¤ê³  í•œë‹¤. 
(ê·¼ë° ì´ì •ë„ ì°¨ì› ì¤„ì´ëŠ” ê²ƒì´ í° ì˜ë¯¸ê°€ ìžˆìœ¼ë ¤...ë‚˜?)

ìžì„¸í•œ ê³¼ì •ì€ [ì´ ë…¼ë¬¸](https://arxiv.org/pdf/2103.15316.pdf)ì— ìžˆë‹¤ê³  í•œë‹¤...

ìž ê·¸ëŸ¬ë©´ ë‹¤ì‹œ ì²˜ìŒ ìˆ˜ì‹ì„ ë³´ìž.

$$
\tilde{e} = T(e) = (e - \mu)W
$$

ì—¬ê¸°ì„œ $e$ëŠ” $E(x)$ì´ë‹¤. ì¦‰, ë¬¸ìž¥ì„ ì¸ì½”ë”ì— ë„£ì–´ì„œ ë‚˜ì˜¨ ë²¡í„°ì¸ë°, ì´ ë²¡í„°ë¥¼ ì„ í˜• ë³€í™˜ ì‹œí‚¤ëŠ” ê²ƒì´ ë°”ë¡œ $T(e)$ì´ê³ , ê·¸ ê²°ê³¼ê°€ $\tilde{e}$ì´ë‹¤. ê·¸ë¦¬ê³  ê·¸ ê³„ì‚° ë°©ë²•ì´ ë°”ë¡œ $(e - \mu)W$, ì¦‰ $(e - \mu)(U\sqrt{\Lambda^{-1}})$ì´ë‹¤! 

ì´ë ‡ê²Œ ëª‡ ê°œì˜ ë¬¸ìž¥ë§Œìœ¼ë¡œ $W$ëž‘ $\mu$ë¥¼ êµ¬í•´ ë†“ì„ ìˆ˜ ìžˆê³ , ì´ë ‡ê²Œ êµ¬í•œ $\tilde{e}$ë¥¼ ì‚¬ìš©í•´ì„œ 3ë‹¨ê³„ë¡œ ë„˜ì–´ê°„ë‹¤. 

ì •ë¦¬ : 
1. knowledge-seeking turnì— í•´ë‹¹í•˜ëŠ” ë¬¸ìž¥ ëª‡ ê°œë¥¼ ì¸ì½”ë” (ëª¨ë¸)ì— ë„£ì–´ì„œ ë²¡í„°ë¥¼ êµ¬í•˜ìž. 
2. ê·¸ ë²¡í„°ë“¤ì„ ì‚¬ìš©í•´ì„œ ì´ë ‡ê²Œ ì €ë ‡ê²Œ í•˜ë©´ ì„ í˜• ë³€í™˜ ë²¡í„°ê°€ ë‚˜ì˜¨ë‹¤.
3. ê·¸ ì„ í˜• ë³€í™˜ ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ë©´ ì´ì œ ë‹¤ë¥¸ ë¬¸ìž¥ë“¤ë„ $\tilde{e}$ë¡œ ë³€í™˜í•  ìˆ˜ ìžˆë‹¤. ì´ê²ƒì€ PCAëž‘ ì´ë¡ ì ìœ¼ë¡œ ê°™ë‹¤ê³  í•œë‹¤.

## 3. Density Estimation

ì´ì œ, non-knowledge-seeking turn ë¬¸ìž¥ë“¤ì„ ê°€ì ¸ë‹¤ê°€, 2ë‹¨ê³„ì˜ ì„ í˜• ë³€í™˜ì„ í•´ì„œ ${\tilde{e}_1^{NK}, ...,\tilde{e}_N^{NK}}$(ë³€í˜•ëœ ë¬¸ìž¥ë“¤)ì„ ì–»ì„ ìˆ˜ ìžˆë‹¤. ì´ì œ ì´ê±°ë¥¼ unit vectorë¡œ normalizeí•œë‹¤.
ê·¸ ë‹¤ìŒì—, Gaussian Mixture Model(GMM) ê°™ì€ ìž‘ì€ ëª¨ë¸ì„ í›ˆë ¨í•œë‹¤. 

ê²°ê³¼ì ìœ¼ë¡œ, ì¸ì½”ë” Eì™€, ì„ í˜•ë³€í™˜ Tì™€, ìž‘ì€ ëª¨ë¸ Dë¥¼ ì´ìš©í•´ ë¬¸ìž¥ì˜ ì ìˆ˜ë¥¼ ë‚¼ ìˆ˜ ìžˆë‹¤. 
$$
D(T(E(x)))
$$

ì´ê²Œ threshold $\eta$ë¥¼ ë„˜ìœ¼ë©´ non-knowledge-seeking turnì´ë¼ê³  íŒë‹¨í•˜ë©´ ëœë‹¤! $\eta$ëŠ” training setì—ì„œ ì ë‹¹í•˜ê²Œ ì •í•˜ë©´ ëœë‹¤. 

ì´ë ‡ê²Œ í•˜ë©´ ì•žìœ¼ë¡œì˜ non-knowledge-seeking turnì¸ ë¬¸ìž¥ë“¤ì€ ë†’ì€ ê°’, ì•„ë‹Œ ê²ƒë“¤ì€ ë‚®ì€ ê°’ìœ¼ë¡œ ë‚˜ì˜¤ê²Œ ëœë‹¤!

# ì–¼ë§ˆë‚˜ ì¢‹ì€ë°?

![](https://velog.velcdn.com/images/vkehfdl1/post/be01a514-323a-479f-b900-ce79237f7d59/image.png)

ì´ˆë¡ìƒ‰ì´ ìœ„ REDE ê¸°ë²•ì´ê³ , ì£¼í™©ìƒ‰ê³¼ íŒŒëž‘ìƒ‰ì€ ë³¸ëž˜ ê¸°ë²•ìœ¼ë¡œ fine-tuning í•œ ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  xì¶•ì€ knowledge-seeking turn ë¬¸ìž¥ë“¤ì¸ë°, ì´ê²ƒë“¤ì´ ì—„ì²­ ì ì„ ë•Œì—ë„ REDEëŠ” ì™„ì „ ë†’ì€ ì„±ëŠ¥ì„ ë‚´ê³  ìžˆë‹¤.


# ì§ì ‘ í•´ ë³´ì•˜ë‹¤~

![](https://velog.velcdn.com/images/vkehfdl1/post/e2681917-fc5b-4e12-afd1-e1fbd1904ff2/image.jpeg)

ì§„ì§œ ìž˜ëœë‹¤. ì´.ì™œ.ì§„?
DSTC11-Track5 ë°ì´í„°ì…‹ìœ¼ë¡œ ì§ì ‘ í•´ë³´ì•˜ë‹¤. ë…¼ë¬¸ì—ì„œ ë‚˜ì˜¨ DSTC9-Track1ì˜ ì‹¬í™”ë²„ì „?ì´ë¼ê³  í•  ìˆ˜ ìžˆë‹¤. 

í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤‘ 500ê°œë¥¼ ìƒ˜í”Œí•´ì„œ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í–ˆë‹¤. non-knowledge-seek turn ë°ì´í„° ì—­ì‹œ ë¶€ì¡±í•œ ìƒí™©ì´ ìžˆì„ ê²ƒì´ë¼ê³  í™•ì‹ í–ˆê¸°ì—, ì´ê²ƒì— ëŒ€í•œ ì‹¤í—˜ë„ ì§„í–‰í–ˆë‹¤. 

+ validation ë°ì´í„°ë¡œ thresholdë¥¼ ì°¾ì•˜ê³ , ì´ë¥¼ ìœ„í•´ train setì˜ 20% ë§Œí¼ë§Œ ì‚¬ìš©í–ˆë‹¤.

ë¨¼ì €, non-knowledge-seek turn ë°ì´í„°ë¥¼ 50ê°œë¡œ ê³ ì •í•˜ê³  ì‹¤í—˜í•´ë³´ì•˜ë‹¤. 

| knowledge seek trun ë°ì´í„° ìˆ˜ | 2-shot | 3-shot | 5-shot | 10-shot |
| :-: | - | - | - | - |
|Precision |0.9141|	0.8928|	0.875|	0.9127|
| Recall |0.9459	|0.9652|	0.9729|	0.9691|
| F1 Score | 0.9297	|0.9276|	0.9213|	0.9401|

knowledge-seek turn ë°ì´í„° ìˆ˜ê°€ 10-shotì´ ê°€ìž¥ ì¢‹ê¸°ëŠ” í–ˆëŠ”ë° 2~5shotê¹Œì§€ëŠ” ë³„ ì°¨ì´ê°€ ë‚˜ì§€ ì•ŠëŠ”ë‹¤. ì°¨ì´ í­ë„ í¬ì§€ ì•Šì•„ì„œ, 2ê°œì˜ ë°ì´í„°ë§Œ ìžˆì–´ë„ ì—„ì²­ ê´œì°®ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. 


ê·¸ë¦¬ê³ , knowledge-seek turn ë°ì´í„°ë¥¼ 10ê°œë¡œ ê³ ì •í•˜ê³  ì‹¤í—˜í–ˆë‹¤.

| Non-knowledge seek trun ë°ì´í„° ìˆ˜ | 5-shot | 10-shot | 50-shot | 100-shot |
| :-: | - | - | - | - |
| Precision | 0.87188|	0.89605|	0.9127|	0.9471
| Recall | 0.94594	|0.96525|	0.9691	|0.9691
|F1 Score | 0.90740	|0.92936	|0.9401	|0.95801

ì´ ë°ì´í„°ê°€ 15ê°œë°–ì— ë˜ì§€ ì•Šì•„ë„ 0.9 ì •ë„ì˜ F1 Scoreê°€ ë‚˜ì™€ì¤€ë‹¤. ìƒê°ë³´ë‹¤ ì„±ëŠ¥ì´ ë˜ê²Œ ê´œì°®ë‹¤! ë…¼ë¬¸ì—ëŠ” ì•ˆ ë‚˜ì™€ ìžˆì–´ì„œ ëª°ëžëŠ”ë°, ì´ê±° ë‘ ë ˆì´ë¸” ëª¨ë‘ ë§Žì§€ ì•Šì•„ë„ ê´œì°®ë‹¤. 10ê°œ-10ê°œ ì •ë„ë§Œ ë§Œë“¤ ìˆ˜ ìžˆìœ¼ë©´ ì“¸ë§Œí•œ ì„±ëŠ¥ì„ ë½‘ì•„ì¤„ ê²ƒ ê°™ë‹¤. 

ì°¸ê³ ë¡œ, í•´ë‹¹ ë°ì´í„°ì…‹ìœ¼ë¡œ supervised learningí•œ ëª¨ë¸ë“¤ì€ 0.99ëŠ” ê°€ë³ê²Œ ë„˜ëŠ” F1 scoreë¥¼ ë³´ì—¬ì£¼ê¸°ëŠ” í•œë‹¤... ê·¸ëž˜ë„, ë°ì´í„°ì…‹ 20ê°œ ì •ë„ë§Œ êµ¬ì¶•í•  ìˆ˜ ìžˆìœ¼ë©´ ëœë‹¤ëŠ” ê²ƒì´ REDEì˜ ì—„ì²­ë‚œ ë©”ë¦¬íŠ¸ ë˜ì‹œê² ë‹¤~

# ì½”ë“œ

[RAGchain](https://github.com/NomaDamas/RAGchain)ì—ì„œ ë°”ë¡œ ì¨ ë³¼ ìˆ˜ ìžˆë‹¤!
ì½”ë“œ ì„¤ëª…ì€ ìƒëžµí•œë‹¤. 

![](https://velog.velcdn.com/images/vkehfdl1/post/4c26c110-112b-4b5f-9c40-04e6e8529c2d/image.webp)

```python
from typing import List, Optional

import numpy as np
from langchain.embeddings import OpenAIEmbeddings
from langchain.schema.embeddings import Embeddings
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import roc_curve
from sklearn.mixture import GaussianMixture


def _normalize_vectors(vectors):
    return vectors / np.linalg.norm(vectors, axis=1, keepdims=True)


class RedeSearchDetector:
    """
    This class is implementation of REDE, the method for detect knowledge-seeking turn in few-shot setting.
    It contains train function for your custom model, and inference function for detect knowledge-seeking turn.
    You will need non-knowledge seeking turn dialogues. Plus, it will be great you have few knowledge-seeking turn dialogues.

    The method is implementation of below paper:

    @article{jin2021towards,
      title={Towards zero and few-shot knowledge-seeking turn detection in task-orientated dialogue systems},
      author={Jin, Di and Gao, Shuyang and Kim, Seokhwan and Liu, Yang and Hakkani-Tur, Dilek},
      journal={arXiv preprint arXiv:2109.08820},
      year={2021}
    }
    """

    def __init__(self,
                 threshold: float,
                 embedding: Embeddings = OpenAIEmbeddings()):
        """
        :param embedding: Encoder model for encoding sentences to vectors. Langchain Embeddings class. Default is OpenAIEmbeddings.
        :param threshold: Threshold for classify knowledge-seeking turn. If the score is higher than threshold, classify as non-knowledge-seeking turn.
        Find this threshold by using training data that you own. (e.g. 0.5)
        """
        self.embedding = embedding  # Encoder model for encoding sentences to vectors
        self.threshold = threshold
        self.mu = None
        self.omega_matrix = None  # Omega matrix for linear transformation.
        self.gmm = None  # Gaussian Mixture Model for classify knowledge-seeking turn.
        self.norm = None  # Norm for normalize to unit vector.

    def find_representation_transform(self,
                                      knowledge_seeking_sentences: List[str],
                                      L: Optional[int] = None,
                                      ):
        """
        :param knowledge_seeking_sentences: Knowledge-seeking turn sentences. List[str].
        :param L: Number of dimensions of the transformed representation. If None, use whole dimension.
        Default is None.
        """
        # find mu
        vectors = np.array(self.embedding.embed_documents(knowledge_seeking_sentences))
        self.mu = np.mean(vectors, axis=0)

        # get covariance matrix
        sigma = np.cov(vectors.T)

        # singular value decomposition
        U, S, V = np.linalg.svd(sigma)

        # find omega matrix
        self.omega_matrix = U @ np.sqrt(np.linalg.inv(np.diag(S)))
        if L is not None:
            self.omega_matrix = self.omega_matrix[:, :L]

        print("REDE representation transform done.")

    def representation_formation(self, vectors: np.ndarray) -> np.ndarray:
        """
        :param vectors: Vectors after encoding. np.ndarray.
        :return: Transformed vectors. np.ndarray.
        """
        return (vectors - self.mu) @ self.omega_matrix

    def train_density_estimation(self,
                                 gmm: GaussianMixture,
                                 non_knowledge_seeking_sentences: List[str]):
        """
        :param gmm: Gaussian Mixture Model for classify knowledge-seeking turn. GaussianMixture. n_components must be 1.
        :param non_knowledge_seeking_sentences: Non-knowledge-seeking turn sentences. List[str].
        """
        self.gmm = gmm
        sentence_vectors = np.array(self.embedding.embed_documents(non_knowledge_seeking_sentences))
        transformed_vectors = np.array(
            [self.representation_formation(sentence_vector) for sentence_vector in sentence_vectors])
        # normalize to unit vector
        transformed_vectors = _normalize_vectors(transformed_vectors)

        self.gmm.fit(transformed_vectors)

    def find_threshold(self,
                       valid_knowledge_seeking_sentences: List[str],
                       valid_non_knowledge_seeking_sentences: List[str]):
        """
        Find threshold using Youden's index from validation data predictions.
        :param valid_knowledge_seeking_sentences: knowledge-seeking turn sentences for validation. List[str].
        You can put same sentences that you used for find_representation_transform function.
        :param valid_non_knowledge_seeking_sentences: non-knowledge-seeking turn sentences for validation. List[str].
        """
        true_scores = self._get_density_score(valid_knowledge_seeking_sentences)
        false_scores = self._get_density_score(valid_non_knowledge_seeking_sentences)

        y_true = np.concatenate([np.ones_like(true_scores), np.zeros_like(false_scores)])
        y_score = true_scores + false_scores

        fpr, tpr, thresholds = roc_curve(y_true, y_score)
        idx = np.argmax(fpr - tpr)
        self.threshold = thresholds[idx]

        precision, recall, f1 = self._calculate_metrics(y_true, y_score)
        print(f"Precision: {precision}")
        print(f"Recall: {recall}")
        print(f"F1: {f1}")

        return self.threshold

    def detect(self, sentences: List[str]) -> bool:
        """
        :param sentences: Sentences to detect. List[str].
        :return: True if the sentence is knowledge-seeking turn, else False. bool.
        """
        score = self._get_density_score(sentences)[0]
        return score < self.threshold

    def evaluate(self, test_knowledge_seeking_sentences: List[str],
                 test_non_knowledge_seeking_sentences: List[str]):
        """
        Evaluate rede search detector using test dataset.
        :param test_knowledge_seeking_sentences: knowledge-seeking turn sentences for test. List[str].
        :param test_non_knowledge_seeking_sentences: non-knowledge-seeking turn sentences for test. List[str].
        """
        true_scores = self._get_density_score(test_knowledge_seeking_sentences)
        false_scores = self._get_density_score(test_non_knowledge_seeking_sentences)

        y_true = np.concatenate([np.ones_like(true_scores), np.zeros_like(false_scores)])
        y_score = true_scores + false_scores

        precision, recall, f1 = self._calculate_metrics(y_true, y_score)
        print(f"Precision: {precision}")
        print(f"Recall: {recall}")
        print(f"F1: {f1}")

        return precision, recall, f1

    def _get_density_score(self, sentences: List[str]) -> List[float]:
        sentence_vectors = np.array(self.embedding.embed_documents(sentences))
        transformed_vectors = np.array([self.representation_formation(np.array(v)) for v in sentence_vectors])
        transformed_vectors = _normalize_vectors(transformed_vectors)
        scores = self._score_vectors(transformed_vectors)
        return scores

    def _score_vectors(self, vectors):
        return [self.gmm.score(vector.reshape(1, -1)) for vector in vectors]

    def _calculate_metrics(self, y_true, y_score):
        predictions = np.where(y_score < self.threshold, 1, 0)
        precision = precision_score(y_true, predictions)
        recall = recall_score(y_true, predictions)
        f1 = f1_score(y_true, predictions)
        return precision, recall, f1
```
